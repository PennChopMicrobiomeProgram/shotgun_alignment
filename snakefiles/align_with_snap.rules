import itertools
import glob
import pathlib
import random

from snakemake.utils import update_config

def get_sample_ids_from_filenames(input_dir, suffix):
    dir_path = pathlib.Path(input_dir)
    input_file_paths = [x for x in dir_path.iterdir() if x.is_file()]
    suffix_paths = [x for x in input_file_paths if x.name.endswith(suffix)]
    return [x.name.replace(suffix, "") for x in suffix_paths]


default_config = {
    "taxonomy_dir": "taxonomy_data",
    "assembly_dir": "reference_data",
    "index_dir": "index_data",
    "input_dir": "input_data",
    "work_dir": "work_data",
    "output_dir": "output_data",
}
update_config(default_config, config)
config = default_config


def iter_partition_ids():
    partition_prefix = "bacteria_"
    index_dir_path = pathlib.Path(config["index_dir"])
    for p in index_dir_path.iterdir():
        if p.name.startswith(partition_prefix):
            partition_id = p.name.replace(partition_prefix, "")
            yield partition_id

# Compute static values to use in rules
PARTITION_IDS = list(iter_partition_ids())
SAMPLE_IDS = get_sample_ids_from_filenames(config["input_dir"], "_R1.fastq")



TARGET_FPS = expand(
    "{out}/{sample_id}.taxa.counts.reduced.standardized",
    out=config["output_dir"], sample_id=SAMPLE_IDS)
print(TARGET_FPS)

rule all:
    input: TARGET_FPS

rule standardize_taxa:
    input:
        config["work_dir"] + "/{sample_id}.taxa.counts.reduced"
    output:
        config["output_dir"] + "/{sample_id}.taxa.counts.reduced.standardized"
    shell:
        "standardize_taxa {config[taxonomy_dir]} < {input} > {output}"
    
rule reduce_multitaxa:
    input:
        config["work_dir"] + "/{sample_id}.taxa.counts"
    output:
        temp(config["work_dir"] + "/{sample_id}.taxa.counts.reduced")
    shell:
        "apply_lca {config[taxonomy_dir]} < {input} > {output}"

rule count_taxa:
    input:
        config["work_dir"] + "/merged_sam_data/{sample_id}.taxa"
    output:
        temp(config["work_dir"] + "/{sample_id}.taxa.counts")
    shell:
        "cut -f 2- {input} | sort | uniq -c > {output}"

rule get_taxa:
    input:
        config["work_dir"] + "/merged_sam_data/{sample_id}.sammin"
    output:
        temp(config["work_dir"] + "/merged_sam_data/{sample_id}.taxa")
    shell:
        "resolve_taxa "
        "{config[index_dir]}/partition_refids.txt "
        "{config[assembly_dir]}/bacteria_assembly_summary.txt "
        "< {input} > {output}"

rule sort_alignments:
    input:
        config["work_dir"] + "/merged_sam_data/{sample_id}.sammin.unsorted"
    output:
        config["work_dir"] + "/merged_sam_data/{sample_id}.sammin"
    shell:
        "sort < {input} > {output}"

rule merge_alignments:
    input:
        lambda wildcards: expand(
            config["work_dir"] + "/sam_data/{sample_id}/bacteria_{partition_id}.sammin",
            sample_id=wildcards.sample_id,
            partition_id=PARTITION_IDS,
        )
    output:
        temp(config["work_dir"] + "/merged_sam_data/{sample_id}.sammin.unsorted")
    shell:
        "mkdir -p merged_sam_data; "
        "rm -f {output}; "
        "for FP in {input}; do "
        "    cat $FP >> {output}; "
        "done"

rule snap_align_paired:
    input:
        read1=config["input_dir"] + "/{sample_id}_R1.fastq",
        read2=config["input_dir"] + "/{sample_id}_R2.fastq",
        genome=config["index_dir"] + "/bacteria_{partition_id}/Genome",
        genomeindex=config["index_dir"] + "/bacteria_{partition_id}/GenomeIndex",
        indexhash=config["index_dir"] + "/bacteria_{partition_id}/GenomeIndexHash",
        overflow=config["index_dir"] + "/bacteria_{partition_id}/OverflowTable"
    output:
        temp(config["work_dir"] + "/sam_data/{sample_id}/bacteria_{partition_id}.sammin")
    params:
        indexdir=config["index_dir"] + "/bacteria_{partition_id}"
    threads: 8
    shell:
        "snap-aligner paired {params.indexdir} {input.read1} {input.read2} "
        "-t {threads} -D 5 -om 5 -omax 100 "
        "-o -sam - | "
        "convert_sam > {output}"

rule unzip_fastq:
    input:
        config["input_dir"] + "/{sample_id}_{read_idx}.fastq.gz",
    output:
        temp(config["input_dir"] + "/{sample_id}_{read_idx}.fastq")
    shell:
        "gunzip -c {input} > {output}"

rule clean:
    shell: "rm -rf {config[work_dir]}/*"
